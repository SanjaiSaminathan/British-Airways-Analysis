# -*- coding: utf-8 -*-
"""britishairways2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lyFIucFb-1lFzJg66q3c0je3kW48FowE
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

import os
import pandas as pd

# Assuming df is your DataFrame
# df = ...

# Define the directory and file path within Colab
directory = 'data'
file_path = os.path.join(directory, 'customer_booking.csv')

# Check if the directory exists, and create it if it doesn't
if not os.path.exists(directory):
    os.makedirs(directory)

# Save the DataFrame to a CSV file in the specified directory
df.to_csv(file_path, index=False)

print(f"File saved to {file_path}")

import pandas as pd

# Specify the correct encoding (e.g., 'latin-1', 'iso-8859-1') based on your file
file_path = '/content/gdrive/MyDrive/Text/customer_booking.csv'
df = pd.read_csv(file_path, encoding='latin-1')

# Perform operations on the DataFrame as needed
# Example: df['new_column'] = df['old_column'] * 2

# Save the DataFrame to a CSV file
output_file = 'output_dataset.csv'
df.to_csv(output_file, index=False)

print(f"File saved to {output_file}")

# Display the first few rows of the dataset
print("First 5 rows of the dataset:")
print(df.head())

# Display basic information about the dataset
print("\nDataset information:")
print(df.info())

# Summary statistics of numerical columns
print("\nSummary statistics:")
print(df.describe())

# Check for missing values
print("\nMissing values:")
print(df.isnull().sum())

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import OneHotEncoder
import matplotlib.pyplot as plt

# Load the preprocessed dataset
file_path = 'output_dataset.csv'
df = pd.read_csv(file_path)

# Assuming 'booking_complete' is the correct column name indicating customer booking (1 for booking, 0 for no booking)
y = df['booking_complete']  # Replace 'booking_complete' with the actual column name from your dataset
X = df.drop('booking_complete', axis=1)  # Features (drop the target column)

# Check the data types of columns
print(X.dtypes)

# Handle categorical variables using OneHotEncoder
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()

# If there are categorical columns, encode them
if categorical_cols:
    encoder = OneHotEncoder(drop='first', sparse_output=False)  # updated sparse to sparse_output
    X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]))
    X_encoded.columns = encoder.get_feature_names_out(categorical_cols)  # updated method name

    # Drop original categorical columns from X and concatenate encoded columns
    X = X.drop(categorical_cols, axis=1)
    X = pd.concat([X, X_encoded], axis=1)

# Split data into training (60%), temp (40%)
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)

# Split temp data into validation (50% of temp -> 20% of original) and test (50% of temp -> 20% of original)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

# Initialize RandomForestClassifier
rf_model = RandomForestClassifier(random_state=42)

# Train the model
rf_model.fit(X_train, y_train)

# Predict on the validation set
y_val_pred = rf_model.predict(X_val)

# Evaluate the model on the validation set
val_accuracy = accuracy_score(y_val, y_val_pred)
print(f'Validation Accuracy: {val_accuracy:.2f}')
print("Validation Classification Report:")
print(classification_report(y_val, y_val_pred))

# Predict on the test set
y_test_pred = rf_model.predict(X_test)

# Evaluate the model on the test set
test_accuracy = accuracy_score(y_test, y_test_pred)
print(f'Test Accuracy: {test_accuracy:.2f}')
print("Test Classification Report:")
print(classification_report(y_test, y_test_pred))

# Print feature importances
feature_importances = pd.Series(rf_model.feature_importances_, index=X.columns)
print("Top 10 features contributing to the model:")
print(feature_importances.nlargest(10))

# Plot feature importances
feature_importances.nlargest(10).plot(kind='barh')
plt.title('Top 10 Important Features')
plt.xlabel('Feature Importance Score')
plt.show()